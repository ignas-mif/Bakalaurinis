\documentclass{VUMIFPSkursinis}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{caption}
\usepackage{color}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{subfig}
\usepackage{wrapfig}

% Titulinio aprašas
\university{Vilniaus universitetas}
\faculty{Matematikos ir informatikos institutas}
\department{Programų sistemų katedra}
\papertype{Kursinis darbas}
\title{Prekės pardavimo prognozavimas iš vaizdo ir aprašymo naudojant giliuosius neuroninius tinklus}
\titleineng{Predicting advert sale from its image and description using deep learning networks}
\status{4 kurso 5 grupės studentas}
\author{Ignas Bradauskas}
\supervisor{Linas Petkevičius, J. Asist.}
\date{Vilnius – \the\year}

% Nustatymai
%\setmainfont{Palemonas}   % Pakeisti teksto šriftą į Palemonas (turi būti įdiegtas sistemoje)
\bibliography{bibliografija}

\begin{document}
\maketitle

\tableofcontents

\sectionnonum{Įvadas}


Amerikos įmonė „Starbucks“ 2007-ais metais patyrė staigų pelno kritimą (nuo 1 bilijono dolerių iki 504 milijonų). 
Buvo būtina imtis veiksmų ir įmonės valdžia nusprendė pasitelkti naujausias technologijas spręsti šiai problemai. Jie sukūrė lojalumo programą, dovanų kortelių programą ir, turbūt svarbiausia, elektroninę parduotuvę „store.starbucks.com“. \cite{ElCom}
Šis ankstyvus modernizavimasis lėmė įstaigos sėkmę ir leido jai tapti viena garsiausių kavos įmonių pasaulyje. Kiti
pasaulio mažmeninės prekybos verslai irgi neatsilieka ir pradeda naudoti interneto teigiamas paslaugas. Naujausi statistiniai duomenys
teigia, jog elektoroninė komercija (e-komercija) sudaro apie 9,5\% JAV mažmeninės prekybos rinkos dalies ir prognozuojama, jog ši dalis toliau sparčiai augs. Nuo ketivtojo 2017-tųjų ketvirčio iki pirmojo 2018-tųjų ji išaugo \textit{3,9\%  (±0.7\%)}.  \cite{US}  Iš duomenų matoma, jog prekyba internetu, šiais laikais, yra kaip niekad aktuali ir sparčiai auganti. Dėl šios priežasties, šiame darbe bus kuriamas dar daug dėmesio technologijų srityje nesulaukęs GTTE-DNT gilusis modelis.

Modelis spręs prekės pardavimo greičio prognozės uždavinį. Didelę prekės pardavimo proceso dalį užima rinkos analizė. Darbe aprašomas DNT būtų pajėgus atlikti rinkos analizės dalį užvartotoją - kuo trumpesnis laiko tarpas iki prognazuojamo pardavimo, tuo prekė patrauklesnė. Būtų galima nesudėtingai šią metriką paversti į kokią kitą, labiau atitinkančią žmogaus kompiuterio sąveikos geriausias praktikas.

Šiai problemai planuojama naudoti įrankius leisiančius apdoroti duomenis nuotraukas, universalų sakinių užkoduotoją (angl. universal sentance encoder, toliau USE), skirtą apdoroti prekės aprašymą bei pilnai sujungtą neuroninį tinklą. Tinkle turėtų būti optimizuojami parametrai gamma pasiskirstymo funkcijai, siekant sukurti lygtį, lengvai analizuojamą statistinių metodų. DNT apsimokinti panaudotų istorinius skelbimų duomenis. Programa apdorotų šią informaciją ir jos galutinė išvestis būtų tikimybinė prognozė, kada objektas bus parduotas. Tokį rezultatą būtų patogu pritaikyti spręsti prieš tai minėtą uždavinį. Sistema taip pat galėtų paimti visus aktyvius skelbimus, juos surikiuoti pagal prognozuojamą pardavimo datą arba, kitais žodžiais, pagal jų patrauklumą ir pradiniame puslapyje pavaizduoti numatomai sėkmingiausius.

\textbf{Darbo tikslas} - suformuluoti prekių pardavimo laiko progozavimo uždavinį, kuriuo remiantis bus sukurta ir išbandyta prototipinė sistema naudojanti giliuosius neuroninius tinklus.

\vspace{3mm} %5mm vertical space

\textbf{Darbo uždaviniai:}
\begin{enumerate}
  \item Atlikti DNT apžvalgą.% svarbu palyginti su kitomis sistemomis 
  \item Sudaryti netikrų duomenų rinkinį.
  \item Suformuluoti prekių pardavimo prognozavimo uždavinį GN tinklams.
  \item Sukurti prototipą ir atlikti tikslumo vertinimą.
\end{enumerate}

\textbf{Laukiami rezultatai}: Tyrimo proceso eigoje bus praktiškai pritaikomos žinios ir kuriamas DNT, kuris, bus pajėgus atlikti prekės pardavimo prognozę su 85\% (±5\%)tikslumu. Taip pat bus analizuojama aktuali uždavinui medžiaga susidedanti iš: dirbtinių neuroninių tinklų veikimo principų, universalaus sakinių užkoduotojo, iš anksto apmokinto ResNet tinklo pritaikymo kitam uždaviniui, gamma skirstinio, uždaviniui aktualių statistikos skyrių. Atsižvelgiant į darbo kūrimo sėkmingumą ir spartą, bus priimamas sprendimas ar į darbą įtraukti cenzūruotų duomenų pritaikymą, t.y. duomenų apie įvykio nebuvimą panaudojimą tinklo apmokinimui.

\textbf{Tyrimo metodas}: Šis tyrimas bus paremtas kiekybiniu metodu, nes bus daromas sisteminis tyrimas, kurio metu bus tiriamas GTTE-DNT tinklo sugeneruotos prognozės procentalus atitikimas realiems duomenims.

\textbf{Numatomas darbo atlikimo procesas}: Darbo atlikimo procesas bus iteratyvus, t.y. nebus apibrėžiami visi sistemos reikalavimai pačioje aplikacijos kūrimo proceso pradžioje. Vietoje to,sistema bus statoma ciklais, mažomis užduotimis. Taip siekiama sumažinti riziką ir optimizuoti rezultatus.

Kiekviename cikle bus išsikeliami tikslai, gilinimasi į šaltinius, realizuojama praktinė programos dalis arba rašto darbo dalis ir kursinio vadovui pristatomi rezultatai.

\textbf{Darbui aktualūs literatūriniai šaltiniai}: Didelė dalis šios medžiagos analizės remsis Egil Martinsson „WTTE-RNN : Weibull Time To Event Recurrent Neural Network“ magistro darbu,  kuriame buvo sprendžiama sudėtingesnė ir bendresnė prognozės uždavinio forma remiantis Weibull skirstinio parametrų optimizacija.

Taip pat bus pasitelkiami kiti šaltiniai aiškinantys atitinkamas temas, t.y. apmokinimo perdavimui bus naudojami Stanford cs231 užrašai, siekiant našiau dirbti ir skirti mažiau laiko žemo  lygio kodui bus naudojamas TensorFlow karkasas ir jo dokumentacija. USE analizei bus naudojamas Google mokslininkų parašytas Universal Sentence Encoder 2018 mokslinis darbas. Gamma skirstiniui aprašyti bus remimasi Thomas P. Minka „Estimating a Gamma distribution“. Kiti šaltiniai dar nėra numatyti arba yra per mažai jais remimasi, kad būtų vertinga juos minėti šioje skiltyje.

Darbo autorius naudos keras karkasą kurti modeliui, taip pat bus naudojamos python beautiful soup ir TorRequest bibliotekos kurti interneto gremžėją \textit{(angl. web scrapper)} skirtą sudaryti duomenų rinkinį. 


\section{Metodologinė dalis}
% Medžiagos darbo tema dėstymo skyriuose pateikiamos nagrinėjamos temos detalės:
% pradinė medžiaga, jos analizės ir apdorojimo metodai, sprendimų įgyvendinimas,
% gautų rezultatų apibendrinimas. Šios dalies turinys labai priklauso nuo darbo
% temos. Skyriai gali turėti poskyrius ir smulkesnes sudėtines dalis, kaip
% punktus ir papunkčius.

% Medžiaga turi būti dėstoma aiškiai, pateikiant argumentus. Tekstas dėstomas
% trečiuoju asmeniu, t.y. rašoma ne „aš manau“, bet „autorius mano“, „autoriaus
% nuomone“. Reikėtų vengti informacijos nesuteikiančių frazių, pvz., „...kaip jau
% buvo minėta...“, „...kaip visiems žinoma...“ ir pan., vengti grožinės literatūros
% ar publicistinio stiliaus, gausių metaforų ar panašių meninės išraiškos
% priemonių.

Siekiant geriau suprasti esamų sistemų atliekančių prekių pardavimo analizę veikimo principus, šiame skyriuje bus analizuojamos DNT sąvokos ir architektūriniai modeliai. Kadangi, prototipams rašyti buvo naudojamas aukšto lygio API, bus stengiamasi nesileisti į smulkias implementacijos detales ir formalius įrodymus, bet siekiant sukurti darbą suprantamą skaityotojams neturintiems patirties dirbtinio intelekto sferoje, bus aptariama plati DNT sąvokų ir įrankių aibė.

\subsection{Į priekį sklindančių neuroninų tinklų analizė}

Bendrai tariant, DNT gali būti skirstomi į dvi pagrindines kategorijas. Pirmojoje, vadinamoje FNN  \textit{(angl. feedforward neural network)}, neuronai siunčia savo išvestį tiktrai priekį esantiems sluoksniams (žr. 1 pav.). Antroji kategorija būtų RNN \textit{(angl. recurrent neural network)}, kurios neuronai gali siųsti informacija kitiems neuronams esantiems savo sluoksnyje, neuronams esantiems prieštai esančiame sluoksnyje ir net patiems sau. Toliau RNN nagrinėjami nebus. 

FNN yra DNT, kuriame jungtys tarp neuronų nesuformuoja ciklo \cite{FNNGer, Overview}. Juose neuronai tiesiog siunčia savo išvestį į priekį, toliau esantiems sluoksniams (žr. 1 pav.). 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/simplenn}
  \caption{ Paprastas DNT, susidedantis iš įvesties sluoksnio, dviejų paslėptųjų sluoksnių ir išvesties sluoksnio \cite{Nont}}.
  \label{img:simplenn}
\end{figure}

\subsection{Konvoliucinių (sąsukinių) neuroninių tinklų analizė}

Pats pirmas DNT pasiekęs žmogaus gebėjimus prilygstantį rezultatą ranka rašytų skaitmenų atpažinime, MNIST duomenų rinkinyje, buvo CNN \cite{MnistBest}. Šiais laikais konvoliucinių neuroninių tinklų architektūrinis modelis ženkliai pranoksta savo konkurentus vaizdų analizės srityje. Šis DNT išsiskiria tuo, kad naudoja filtrų seką ant grynųjų iliustracijų pixelių duomenų, siekiant išgauti aukštesniojo lygio požymius. Juos išmokus modelis naudojamas klasifikavimui. CNN susideda iš trijų dalių: 

\begin{enumerate}
  \item \textbf{Konvoliuciniai sluoksniai}, kūrių pagrindinis skirtumas nuo pilnai sujungtųjų sluoksnių yra tas faktas, kad jų kiekvienas neuronas yra sujungtas tiktai su mažu lokaliu prieš tai esančio sluoksnio neuronų poaibiu. Juose iliustracijos pereina per tam tikrą skaičių filtų. Kiekvienam subregionui (žr. pav. 2) sluoksnis pritaiko matematinių operacijų rinkinį siekiant gauti reikšmę išeigos požymių žemėlapyje \textit{(angl. output feature map)}. Konvoliuciniai sluoksniai tada paprastai pritaiko ReLU aktyvacijos funkciją savo išeigai. 
  
  \begin{figure}[H]
    \centering
    \includegraphics[scale=1]{img/conv}
    \caption{ Konvoliucinio sluoksnio neuronas atlieka konvoliucijos operaciją 3x3 laukui \cite{Nont}}.
    \label{img:conv}
  \end{figure}
  
  \item \textbf{Telkimo sluoksniai} \textit{(angl. pooling layers)}, kurie, iš prieš tai esančių sluoksnių gautą informaciją suagreguoja į reikšmių poaibį, taip ženkliai sumažinant reprezentacijos dimencionalumą \cite{Pooling}. Telkimo sluoksnio paskirtis - sumažinti CNN sudėtingumą. 

  Panašiai kaip konvoliuciniuose sluoksniuose, neuronai esantys telkimo sluoksnyje yra sujungti su kvadrado formos regionu. Pagrindinis skirtumas tarp konvoliucinio sluoksnio ir telkimo sluoksnio yra tai, kad telkimo sluoksnis nėra parametrizuotas. Tai reiškia, jog neuronai esantys telkimo sluoksnyje neturi hiperparametų, kurie gali būti koreguojami mokymo proceso eigoje. Vietoj to yra naudojama statinė funkcija sluoksnio įeigai.

  Vienas iš dažniausiai naudojamų telkimo tipų yra maksimalaus telkimo tipas. Tai metodas, kurio metu įvesties matricoje surandama didžiausia reikšmė ir išvedama tik ji. Taip pašalinamos likusios matricos reikšmės ir išvestis būna, duomenų kiekiu, mažesnė negu įvestis (žr. 3 pav).

  \begin{figure}[H]
    \centering
    \includegraphics[scale=1]{img/pooling}
    \caption{Telkimo sluoksnis atliekantis maksimalaus telkimo \textit{(angl. max pooling)} operaciją \cite{Nont}.}
    \label{img:pooling}
  \end{figure}


  \item \textbf{Pilnai sujungtieji sluoksniai}, kurie atlieka klasifikavimą požymiams, gautiems iš konvoliucinių sluoksnių, supaprastintiems telkimo sluoksnių. Šie sluoksniai atitinka FNN struktūrą, t.y. kiekvienas mazgas yra sujungtas su prieš jo sluoksnį esančio sluoksnio kiekvienu mazgu. \cite{TFMnist}
\end{enumerate}

Paprastai, CNN yra sudarytas iš konvoliucinių modulių rinkinio, kuris atlieka požymių išgavimą. Kiekvienas modulis susidaro iš konvoliucinio sluoksnio ir įkandin sekančio telkimo sluoksnio. Paskutinysis konvoliucinis modulis priekį savęs turi vieną arba keletą pilnai sujungtųjų sluoksnių kurie atlieka klasifikavimo funkciją. Paskutinysis pilnai sujungtasis sluoksnis savyje turi po vieną mazgą kiekvienai klasifikavimo kategorijai atsovauti. Sugeneruoti vertę nuo nulio iki vieneto šis mazgas naudoja švelnaus maksimumo aktyvacijos funkciją \textit{(angl. softmax function)}. Visų švelnaus maksimumo sugeneruotų reikšmių suma yra lygi vienetui. Mes galime interpretuoti švelnaus maksimumo reikšmes kaip matavimo vienetą atspindintį nuotraukoje esančio objekto atitikimo kategorijai tikimybę. \cite{TFMnist} Švelnaus maksimumo funkcija atrodo taip: 

\begin{equation}
  \delta(z)_j=\frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}}, j = 1, …, K 
\end{equation}

, kai K - įeigos vektorius dimencijos, z - įeigos vektorius,  j - įeigos vektoriuje esančio skaičiaus indeksas.
\subsection{ResNet analizė}

Gilieji tinklai natūraliai sėkmingai išgauna žemojo, vidutiniojo ir aukštojo lygio požymius naudojant daugiasluoksnį architektūrinį stilių. Neseniai padaryti tyrimai atskleidžia, jog tinklo gylis (sustatytų sluoksnių skaičius) yra itin svarbus faktorius tinklo sėkmingumui \cite{VDCN, VDCN2}. 

2015 metais buvo sukurta naujo tipo architektūra, kuri dar labiau peržengė DNT gylio ribas \cite{REDNT}. Tinklas vadinamas giliuoju liekaniniu tinklu \textit{(angl. Deep Residual Network)}, trumpai - ResNet. Šis tinklas pasiekia itin gerus rezultatus turint gilią architektūrą. ResNet konvoliuciniai sluoksniai sugrupuojami į liekaninius blokus ir kiekvienam blokui duodama liekaninė jungtis, kurios tikslas apeiti minėtąjį liekaninį bloką (žr. pav. x). 

Pridedant liekaninių jungčių gaunamas kelias atgaliniam ryšiui leidžiantis tiesiogiai pasiekti ankstesnius sluoksnius. Iš to išplaukia tai, kad galime kurti tinklus esančius daug gilesnius negu paprastieji DNT. Seniau, didesnis sluoksnių kiekis nebūtinai reiškė, jog bus pasiektas geresnis tikslumas. To priežastis tokia, jog, tinklui būnant perdideliam, ansčiau esantys sluoksniai negalėdavo deramai prisitaikyti. ResNet architektūra šią problemą išsprendžia. \cite{Nont}

Tinklo sėkmingumas įrodytas ILSVRC lokalizacijos ir clasifikavimo konkurso bei COCO aptikimo ir segmantavimo iššukio laimėjimu. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/resblock}
  \caption{Liekaninis blokas, susidedantis iš dviejų konvoliucinių sluoksnių ir jį apeinančios liekaninės jungties. Liekaninio blogo įvestis (x) persiunčiama liekaninės jungties ir vėliau pridedama prie bloko rezultato (f(x)) siekiant gauti galutinį išvedinį (f(x) + x) \cite{Nont}}
  \label{img:resblock}
\end{figure}

\subsection{Žinių perdavimas}

Praktikoje labai retai treniruojamas visas konvoliucinis tinklas nuo pradžios iki galo, nes yra gana reta turėti pakankamai didelį duomenų rinkinį. Vietoje to, dažna praktika yra iš anksto ištreniruoti CNN ant labai didelio duomenų rinkinio (pvz.: ImageNet, turinčio virš 14 milijonų iliustracijų ir 1000 skirtingų kategorijų), ir tada ištraukti iš jo požymius. Ištraukti požymiai naudojami apmokinti tinklą norimai užduočiai vykdyti \cite{Cal}. 

Egzistuoja trys pagrindiniai žinių perdavimo scenarijai:

\begin{enumerate}
  \item Butelio kaklo požymių ištraukimas. Šiuo atveju paimamas iš anksto ištreniruotas CNN, pašalinamas jo paskutinis pilnai sujungtasis sluoksnis (šis sluoksnis skirtas klasifikavimui, jame iliustracijai priskiriama viena iš kategorijų), tada likes CNN naudojamas kaip požymių išgavėjas naujam duomenų rinkiniui \cite{Cal}. Požymių išgavėjas tada generuotų didelio ilgio vektorių kiekvienai iliustracijai, kurie būtų naudojami apmokinti prijungtą modelį skirtą klasifikuoti.
  \item CNN sureguliavimas \textit{(angl. Fine-tunning)}. Antroji strategija yre nevien tiktai aukščiausiojo sluoksnio pakeitimas, bet ir iš anksto treniruotojo CNN svorių reguliavimas. Yra įmanoma sureguliuoti visus CNN svorius arba galima palikti keletą ankstyjųjų sluoksnių nepaliestų (su tikslu išvengti permokymo) ir reguliuoti tam tikrą skaičių aukštesniųjų sluoksnių. To priežastis yra pastebėjimas, jog ankstesniesi CNN sluoksniai išgauna labiau abstraktesnius požymius (pavyzdžiui, kraštai ar spalvų dėmes) kas yra gan naudinga dideliam kiekiui užduočių spręsti. Bet tolimesni sluoksniai tampa vis konkretesni duomenų rinkinio klasių detalėms atpažinti.
  \item Iš anksto ištreniruotieji modeliai. Kadaingi ImageNet duomenų rinkiniui, net naudojant keletą GPU, ištreniruoti šiuolaikinį CNN užtrunka nuo dviejų iki trijų savaičių, dažna praktika yra patalpinti savo paskutinįjį kontrolinį tašką \textit{(angl. checkpoint)} internete kitiems žmonėms parsisiųsti ir reguliuoti.
\end{enumerate}

\subsection{USE analizė}

Šiame skyriuje bus aprašomas Google mokslininkų sukurtas universalus sakinių užkoduotojas \textit{(angl. Universal Sentence Encoder)}. Toliau šis pavadinimas bus trumpinamas USE akronimu.  

Gauti duomenų tinklo treniravimui paprastai yra problemų sukelianti užduotis. To pasekoje duomenų mokslininkai susiduria su iššukiu bemokinant daug duomenų reikalaujančius DNT. Dažnai tenka didelią dalį laiko duomenis gremžti iš interneto ar juos bandyti gauti iš trečiųjų šalių (įvairių įmonių kaupiančių duomenis). Taip pat, svarbu paminėti, kad sukurti gerus rezultatus teikiantį tinklą reikia įdėti daug laiko, pastangų ir resursų. Geras būdas išvengti visų šių problemų yra pasinaudoti iš anksto apmokintu tinklu ir perduoti jo žinias savąjąm. Tokį sprendimą siūlo Google USE komanda. Šis modelis teksto sakinius konvertuoja į skaičių vektorius, kurie specifiškai pritaikyti žinių perdavimo užduočiai. 

Nusprendus naudoti USE, taip pat reikia priimti sprendimą kurį iš jų konkrečiai naudoti, nes jie yra du su dviejom skirtingom architektūrom. Šį sprendimą reikia priimti atsižvelgiant į iškeltus dizaino tikslus. Vienas iš USE modelių yra paremtas \textit{transformer} architektūra ir pagrindinė jo savybė yra aukštas tikslumo lygis, didesnio modelio sudėtingumo ir didesnių reikalingų resursų kaina. Kitas, sukurtas pagal \textit{deep averaging network (DAN)} architektūrą, turi intuityvesnę struktūrą su prastesniu pasiektu tikslumu. Abu modeliai yra įgyvendinti Tensorflow ir yra viešai prieinami per Tensorflow Hub.

\subsection{WTTE-RNN analizė}

Šiame skyriuje bus atliekama WTTE-RNN modelio analizė. Skyriaus pradžioje bus pamenami ir trumpai apibūdinami pagrindiniai tinklui suprasti reikalingi mechanizmai ir konceptai. Poskyriuose bus detaliau analizuojamos visos sąvokos. 

Šio modelio pagrindinis tikslas yra analizuoti visus objekto įvykius iki lemtingojo įvykio užbaigiančio tiriamo objekto aktualumą (mirtis, pardavimas, sugedimas) ir pagal juos sugeneruoti skirstinį. Jie yra sudaroma pagal formulę, kuriai reikia dviejų parametrų \textit{alfa} ir \textit{beta}. Nuo šių dviejų parametrų priklauso skirstinio forma. Tai galima tarti, jog DNT turi sugeneruoti šiuos du parametrus. Gero tinklo rezultatas turėtų būti skirstinys turintis didžiają dalį ploto arčiau dabarties, būtent tiems objektams, kuriems labai greitai atsitiks lemtingas įvykis. O tiems, kurie nesusidurs su lemtingu įvykiu dar ilgai, turėtų būti sugeneruojamas labai ploksčias skirstinys. Ją turint apskaičiuoti prognozę yra itin nesudėtinga.

% Praktikos dalyje papasakoti kad aprašytas wtte naudojamas duomenų rinkinys netobulai sueina su manuoju.
Besigilinant į šį modelį didžiaja dalimi bus remimasi Egil Martinsson magistriniu darbu „WTTE-RNN : Weibull Time To Event Recurrent Neural Network“. Šis darbas daugiau dėmesio skiria \textit{nelemiamiems} įvykiams, t.y. rekurentiniams. Toki įvykiai nesustabdo tiriamo objekto gyvavimo, jie gali nuolatos atsitikti jo egzistavimo metu. Įvykiai sustabdantys objekto egzistavimą laikomi išskirtiniais. Turint tai omenyje, galime teigti, kad tinklas tinkamas tokiems uždaviniams kaip: mirties laiko prognozė, prietaiso gedimo laiko prognozė, objekto pardavimo prognozė ir panašiems. Pastarasis uždavinys bus detaliau aptariamas tolimesniuose darbo skyriuose.

\subsubsection{Cenzūruoti duomenys}

Ceuzūravimas yra viena iš ypatingųjų laukimo laikų problemų. Kartais eksperimento metu slenkantis laikas yra pačio eksperimento pamatinis elementas ir mes nevisada galime jį stebėti iki galo. Šis fenomenas vadinamas cenzūra \cite{WTTEBLOG}. 



Minėtieji rekurentiniai įvykiai yra svarbus informacijos šaltinis WTTE-RNN tinklui, jie taip pat suteikia galimybę apmokinimui panaudoti duomenis, kurie vadimani cenzūruotais. Toki duomenys išreiškia, kad įvykis dar neįvykęs, bet mes galime būti tikri, jog jis buvo neįvykęs bent iki dabar. Geras to pavyzdys būtų žmogaus prekių pirkimo duomenys. Tai yra, mes nežinome kiek laiko praeis iki kol vartotojas nusipirks naują prekę, bet mes žinome, kad bus praėję bent tiek laiko kiek praėjo nuo vartotojo praeitos prekės nusipirkimo iki dabar. WTTE-RNN tinklo autorius argumentuoja, jog duomenys apie įvykio nebuvimą yra svarbi bendro duomenų rinkinio dalis. Pasak jo, tinklas pasieks daug geresnius rezultatus jeigu bus apmokinamas cenzūruotais ir necenzūruotais duomenimis. Žemiau pavaizduotame paveiksliuke parodytas pavyzdys abiejų rūšių duomenų (žr. x pav).

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/censored}
  \caption{ Mes turime įvykius pažymėtus $v${\scriptsize t}. Prieš paskutinį užfiksuotą įvykį mes turime \textit{tikruosius} laikus iki įvykio, tad \~{$y$}{\scriptsize $t$} = $y${\scriptsize $t$}. Po to, mes turime cenzūruotą laiką iki įvykio \~{$y$}{\scriptsize $t$} $\leq$ {$y$}{\scriptsize $t$}\cite{WTTEBLOG}.}
  \label{img:censored}
\end{figure}

Atsižvelgiant į tai ar objekto duomenys yra cenzūruoti ar necenzūruoti tinklas turi naudoti skirtingas \textit{loss} funkcijas. Šios funkcijos leidžia sukurti specialiai pritaikytus skirstinius dviems skirtingiems duomenų tipams. Pavyzdžiui, necenzūruotiems duomenims sukurtas skirstinys turėtų turėti daugiausiai svorio prie įvykio (žr. pav. x), necenzūruoti duomenys turi sugeneruoti skirstinį daugiausiai ploto užimantį už užcenzūravimo taško (žr. pav. x), o necenzūruotų ir cenzūruotų duomenų mišinys turi sukurti kompromisuojantį, labiau išbalansuotą skirstinį (žr. pav. x).  

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/pdf1}
  \caption{ Necenzūruotas stebėjimas\cite{WTTEBLOG}.}
  \label{img:pdf1}
\end{figure}


\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/pdf2}
  \caption{ Cenzūruotas stebėjimas\cite{WTTEBLOG}.}
  \label{img:pdf2}
\end{figure}


\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/pdf3}
  \caption{ Cenzūruotas ir necenzūruotas stebėjimas \cite{WTTEBLOG}.}
  \label{img:pdf3}
\end{figure}

Paveikslėliuose matomos formulės yra \textit{loss} formulės gaunamos atsižvelgiant į kokio tipo duomenys gauti. 

%To be continued..? 


\subsection{Skirstiniai}

Atsižvelgiant į tą faktą, jog pagrindinis darbo DNT yra stipriai susijęs su skirstiniais, yra svarbu atlikti šio statistikos mokslo įrankio pagrindų apžvalgą. 

Skirstiniai apibūdina dydžių pasiskirstymo dėsnį. Tai reiškia, kad jie parodo visas įmanomas duomenų rinkinio reikšmes ir kaip dažnai tos reikšmės kartojasi. Turint visa tai omenyje, nebūtų klaidinga tarti, jog skirstinys pavaizduoja duomenų rinkinio formą ir, dažnai, turint duomenų rinkinį yra siekiama pagal jį sugeneruoti kuo tinkamesnį skirstinį. Tai yra trokštama, nes pagal jį galima išvesti didelį kiekį išvadų apie duomenis, pavyzdžiui, padaryti išvadą kurią dieną kokia tikimybė parduoti objektą.

Skirstinių generavimo formulės paprastai turi keletą parametrų skirtų nustatyti jo formą. Šie pasiskirstymo dėsniai taip pat turi keletą svarbių aptarti sąvokų. Aktualiausia darbui iš jų yra \textit{kvantilis}, bet pradėkime ne nuo jo, nes jį paaiškinti taps elementariau žinant apie Culmulative Distribution Function (toliau CDF). 

CDF funkcija (žr. pav. x) apskaičiuoja tikimybę, kad kintamasis įgaus reikšmę mažesnę arba lygią x. Tai yra, jeigu skirstinys atspindi žmonių ugių pasiskirstymą, tai CDF apskaičiuotų kokia tikimybė, jog atsitiktinis žmogus bus mažesnio arba lygaus x ūgiui. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/WeibulCDF}
  \caption{ Weibul CDF funkcija kai λ=5; k=5.}
  \label{img:WeibulCDF}
\end{figure}

Kvantilis yra apskaičiuojamas su Present Point Function (toliau PPF). Ši funkcija (žr. pav. x) yra invertuota CDF funkcija, todėl ji dažnai literatūroje apibūdinama kaip invertuota distribucijos funkcija. Tokia būsena reiškia, jog funkcija pradeda nuo tikimybės ir, turint ją, apskaičiuoja x. Prisimenant prieš tai aptartą ūgių pavyzdį, jį galime pritaikyti šiai funkcijai. Tai yra, jeigu skirstinys atspindi žmonių ūgių pasiskirstymą, tai PPF funkcija galėtų paskaičiuos iki kokio ūgio yra x\% procentų žmonių. Ši sąvoka bus naudojama tolimesniuose skyriuose skaičiuoti per kiek dienų objektas bus parduotas su x\% tikimybe.


\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/WeibulPPF}
  \caption{  Weibul PPF funkcija kai λ=5; k=5.}
  \label{img:WeibulPPF}
\end{figure}

Svarbu paminėti, kad yra sukurti kelių tipų skirstiniai. Galima atspėti, kad originaliame Egil Martinsson straipsnyje, kuriuo stipriai remimasi šiame darbe, buvo remimasi Weibull skirstiniu. Pasak WTTE-RNN autoriaus, šis skirstinys taip pat pasižymi kitomis savybėmis padarančiomis jį itin tinkamu:

\begin{enumerate}
  \item Lengvai diskretizuojamas.
  \item Unimodalus bet išraiškingas.
  \item Vietos-Skalės transformacija.
  \item Regularizacijos mechanizmai.
  \item Kt.
\end{enumerate}

Weibull skirstinys dažnai naudojamas išgyvenimo analizėje ir patikimumo inžinerijoje, bet jis nevienintelis. Kiti šiose srityse dažnai naudojami skirstiniai yra: exponentinis, Log-logistinis, Exponentinis-logaritminis, gamma, Rayleigh, Erlang. Tinklui aprašomam kituose skyriuose galima pritaikyti ne tiktai Weibull skirstinį. Visi skirstiniai turi skirtingas savybes ir skirtingai tinkami specifiniems atvejams. Norint pamatyti kaip skirtingi parametrai paveikia skirtingus skirstinius, autorius sukūrė Weibull ir Gamma skirstinių grafinį palyginimą (žr. pav. x).

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/WeibulVsGamma}
  \caption{  Paveiklėlio legendose matomi parametrai k - forma; θ, λ - mastelis. Grafikuose matomos histogramos atspindi pagal skirstinius sugeneruotus atsitiktinius duomenis. }
  \label{img:WeibulVsGamma}
\end{figure}


\section{Tiriamoji dalis}

Siekiant susidaryti tinkamą WTTE tinklo gerumo įvertinimą, šalia jo, buvo sukurtas paprastesnis DNT. Šis DNT neatsižvelgia į cenzūruotus duomenis ir nekuria skirstinio, visais kitais atžvilgiais jis yra panašus į pagrindinį tyrimo objektą - WTTE tinklą.

Tiriamojoje dalyje bus peržvelgiami abiejų sukurtųjų tinklų modeliai, treniravimo greičiai, tikslumai. Bus pateikiami sugeneruotų duomenų grafikai, skirstiniai. Taip pat, bus aptariamas duomenų surinkimo ir pritaikymo tinklų apmokinimo reikmėms procesas bei sunkumai.


\subsection{Siūlomas modelis}

DNT skirtas spręsti tokį uždavinį turėtų gebėti vykdyti vaizdų analizę. Atsižvelgiant į tai, kad geriausiai vaizdų analizę atlieka CNN, pernaudosime ne ką kitą, bet didelio pasisekimo sulaukusį ResNet modelį, kuris naudoja konvoliucinius sluoksnius ir turi itin didelį gylį. Tai yra pritaikysime butelio kaklo požymių ištraukimo metodą jau esamam ResNet kontroliniam taškui. Tuomet, apmokinsime tinklą pagal savo sutelkto duomenų rinkinio iliustracijas, prijungsime gautą modelį prie FNN tinklo, kuris pagal gautus duomenis generuos \textit{alfa} ir \textit{beta} paremetrus distribucijos \textit{loss} formulei. Prijungimo žingsnyje taip pat bus pridedami kiti parametrai, kaip kuro tipas, kaina, pagaminimo data, aprašymas, kėbulo tipas ir dar keletas kitų. Svarbu paminėti, kad aprašymo duomenys į tinklą bus įtraukiami su USE modelio pagalba. USE užkoduotojas skelbimų aprašymus pavers į skaičių vektorius. Šie vektoriai tada bus prijungiami prie kitų duomenų, tokiu pačiu principu kaip ir ResNet permokinto modelio išvestis. Naudojamas ResNet tinklas turės penkiasdešim sluoksnių, o FNN tinklą sudarys x sluoksniai. FNN tinklo paskutiniojo sluoksnio išvesčiai bus taikoma specialiai pritaikyta \textit{loss} funkcija, kuri ir generuos dvejus reikalingus parametrus sukurti skirstinį. Turint skirstinius, bus galima paskaičiuoti kiekvienam iš jų kvantilį ir gauti iki kurios dienos objektas bus parduotas su pasirinkta tikimybe.

Siekiant susidaryti tinklo sėkmingumo įvertinimą, taip pat buvo sukurtas modelis turintis itin panašią architektūrą. Pagrindinis palyginimui sukurto modelio skirtumas, jo paskutinysis sluoksnis turi vieną išvesties neuroną ir taiko paprastą \textit{loss} funkciją. Šis tinklas sugeneruoja rezultatą forma „Skelbimas bus parduotas per x dienas“.

Turint abiejų tinklų rezultatus bus galima atlikti tikslumo palyginimą.

DNT apsimokinti panaudosime istorinius skelbimų duomenis, kurių forma būtų tokia: 
\begin{equation}
  x_i = [nuotrauka_i; aprašymas_i, kaina_i; spalva_i; ... ; laikas_i;], i = 1, ... , N
\end{equation}

, kai x - skelbimas, i - skelbimo indeksas, N - bendras skelbimų kiekis.

% Čia

% Tikslinga būtų paminėti, jog nemažai tyrimų panašias problemas sprendžia naudodami SVM \cite{IMGPOP,IMGPOP3,IMGPOP4}. Šiame metode kiekvienas duomenų vienetas reprezentuojamas n dimencijų grafike (n atstoja požymių skaičių), kur kiekvieno požymio vertė atstoja kordinatę. Tada klasifikavimas atliekamas randant hiper plokštę \textit{(angl. hyper-plane)}, kuri atskirtia klases minėtame grafike.

% Tai nėra stebinantis atradimas turint omenyje, kad yra atlikta tyrimų teigiančių, jog SVM architektūra gali pasiekti rezultatus prilygtančius standartiniam CNN (žr. pav 5) \cite{IMGPOP5}. Bet svarbu pastebėti, jog galima to priežastis yra tas faktas, kad tų tyrimo rašymo metu dar nebuvo sukurtas ResNet.

% \begin{figure}[H]
%   \centering
%   \includegraphics[scale=0.8]{img/stats}
%   \caption{Skirtingų modulių atpažinimo sėkmingumas skirtingiems duomenų rinkiniams}
%   \label{img:stats}
% \end{figure}

% Tas pats tyrimas perša idėją, jog dažnai visoms problemoms spręsti ir pasiekti maksimalų veiksmingumą naudojami neuroninai tinklai ir, kad rezultatai indikuoja, jog tikroji šios technologijos galia yra išgauti požymiuis. Pasak tyrimo autorių, vertėtų suderinti DNT ir kitus mokinimosi modelius, vietoje tiktai grynų DNT naudojimo. Toks modelis skirtūsi nuo autoriaus kurto, nes šiam darbui buvo naudojamas pilnai neurorinis tinklas. Potencialiai jis turėtų būti greitesnis, bet tai išlieka neaišku, nes tyrime nebuvo lyginami būtent ResNet tinklai su SVM + FNN tinklais.



\subsection{Duomenų rinkinio sudarymas}

Prototipo kūrimo eiga prasidėjo nuo duomenų rinkinio gavimo. Norint, kad duomenys būtų kiek įmanoma tikslesni ir atspindėtų tikrovę buvo galimi du tolimesnių veiksmų variantai iš kur juos įgyti. Tai yra:

\begin{enumerate}
  \item Buvo galima sukurti aplikaciją nuolatos tikrinančią skelbimų portalų skelbimų informaciją.
  \item Buvo galima paprašyti skelbimų portalų administracijos pasidalinti duomenimis. 
  \item Buvo galima duomenis dalinai susimuliuoti.
\end{enumerate} 

Gavus duomenis taip pat reikėjo juos apdoroti, kad jie būtų tinkami apmokyti DNT.

\subsubsection{Duomenų gavimas}

Besprendžiant užduotį buvo bandoma susitarti su keletu skelbimų įmonių ir iš jų gauti duomenų. Buvo kontaktuota ir derėtasi su „Autogidas“, „Autoplius“ ir „Vinted“.

Didžiausius automobilių skelbimių telkinius Lietuvoje nepaneigiamai turi interneto portalai „Autogidas“ ir „Autoplius“, tad buvo susisiekta su jų atstovais. Po ilgo korespondavimosi, Artūras Mizeras, Autoplius.lt portalo vadovas, pasiūlė duoti 5000 skelbimų vienetų, bet matyt persigalvojo, nes bendravimas nutrūko. Autorius įtaria, jog tai yra GDPR pasėkmė, bet tai išlieka neaišku.

Bakalaurinio darbo vadovo pastangomis buvo susitikta su „Vinted“ mašinų mokymo komandos vadovu Dovydu Čeilutka. Nors pradžia atrodė daug žadanti, rezultate, dėl GDPR suvaržymų „Vinted“ duomenų duoti atsisakė.

Dėl fakto, jog komunikavimas su skelbimų prekės ženklų atstovais užėmė didelį laiko tarpą ir dėl bendro laiko trūkumo buvo nuspręsta sukurti interneto gremžėją, kurio paskirtis būtų surinkti skelbimų informaciją, o jų pardavimo laiką tektų, pritaikius išgalvotas taisykles, susimuliuoti. Buvo tikimasi, jog jeigu tinklas sugebės perprasti autoriaus sugalvotas taisykles (negaudamas jokios informacjos apie jas) tada jis taip pat sugebės ir nustatyti tinkamus svorius tikrovės informacijai arba, kitais žodžiais, jis bus pritaikomas realiam panaudos atvejui.

Turint visa tai omenyje, buvo imtasi kurti duomenų gremžėją, kurio pareiga - iš „Autogidas“ portalo surinkti pakankamą kiekį automobilių skelbimų duomenų apmokinti DNT. Pats gremžėjas buvo sukurtas \textit{Python} kalba, jis naudojo būtent inteneto portalų kodo nagrinėjimui pritaikytą biblioteką „Beutiful Soup“ ir „Tor“ tapatybės slėpimo internete protokolą. Pastarasis buvo naudojamas siekiant susidaryti sąlygas greitai surinkti didelį kiekį skelbimų. Jis įgaliojo apeiti „Autogidas“ serverio apsaugas, kurios ribojo vieno IP adreso užklausų kiekį serveriui. Su „Tor“ tapo įmonoma kas kelis šimtus užklausų pakeisti IP adresą ir apeiti prieš tai minėtą apribojimą. Taip sukurta aplikacija sėkmingai surinko virš 2000 skelbimų informaciją.    

Priėmus sprendimą į tinklo architektūrą įtraukti USE modulį, buvo būtina pataisyti gremžėją ir taip pat surinkti automobilių skelbimų aprašymus. Gremžėjas savo darbą atliko sėkmingai ir surinko 2231 skelbimų vienetų duomenis.

\subsubsection{Duomenų apdorojimas}

Prieš duomenis paduodant į DNT yra būtina juos apdoroti. Vienas iš būtinų apdorojimo veiksmų yra tokių parametrų kaip spalva ar defekto buvimas išreiškimas skaitmenimis, tai vadinama \textit{one hot encoding}. Šiam tikslui įgyvendinti buvo sukurta programa, kurią galima rasti darbo prieduose nurodytoje repozitorijoje. Programa taip pat atrenka tiriamus ir netiriamus skelbimo parametrus, nes sukurtas interneto gremžėjas jų paimdavo daugiau negu reikia. Tiriami parametrai yra pagaminimo data, kaina Lietuvoje, rida, kuro tipas, kėbulo tipas, vairo padėtis, defektai, miestas. Visi šie parametrai buvo įvertinami butent jiems pritaikytų taisyklių. Dauguma jų sudaro paprastus rėžius duodančius skirtingą kiekį taškų duomenims patenkantiems ir nepatenkantiems į juos.

\begin{table}[H]\footnotesize
  \centering
  \caption{Skelbimų pardavimų įvertinimo taisyklės.}
  {\begin{tabular}{|l|c|c|} \hline
    Požymis & Kriterijus & Taškai \\
    \hline
    Metai & > 2015         & -50       \\
         & [2015; 2010)   & 0      \\
         & [2010; 2005)   & 50      \\
         & [2005; 2000]   & 100      \\
         & < 2000   & 150      \\
    \hline
    Kaina & > 15000         & 150\\
        & [15000; 10000)   & 100      \\
        & [10000; 8000)   & 80      \\
        & [8000; 6000)   & -30      \\
        & [6000; 2000)   & -50     \\
        & [2000; 1000]   & -80     \\
        & < 1000   & -100     \\
    \hline
    Rida & > 400000         & 100\\
        & [400000; 300000)   & 60      \\
        & [300000; 200000)   & 40      \\
        & [200000; 100000]   & -40      \\
        & < 100000   & -60     \\
        & Neįvardina   & 50     \\
    \hline
    Kuro tipas & Dyzelinas   & -20\\
        & Benzinas   & 10      \\
        & Kita   & -30      \\
    \hline
    Kėbulo tipas & Hečbekas   & -20\\
        & Sedanas   & -30      \\
        & Visureigis   & -10      \\
        & Kita   & 40     \\
    \hline
    Vairo padėtis & Kairėje   & 0\\
        & Kita   & 50      \\
    \hline
    Defektų buvimas & Yra   & 50\\
        & Nėra   & 0      \\
    \hline
    Automobilio vieta & Vilnius   & -30\\
        & Kaunas   & -20      \\
        & Klaipėda   & -10      \\
        & Marijampolė   & 0      \\
        & Kita   & 30      \\
    \hline
  \end{tabular}}
  \label{tab:table example}
\end{table}

Lentelėje matomi įnvertinimai už skirtingus skelbimo parametrus (žr. lent. 1). Nuotraukos taip pat įvertinamos. Tai pasiekiama duodnt taškus už nuotrauką, o jie suskaičiuojami įvertinant parametrus, kurie atsispindi nuotraukose. T.y spalva, kėbulo tipas, automobilio pagaminimo data. Baigus vertinti visus skelbimo kriterijus taškai susumuojami ir gautas rezultatas laikomas dienų prireikusių parduoti objektą kiekiu. Jeigu automobilis po įvertinimo proceso turi neigiamą kiekį taškų, jie nunulinami. 

WTTE tinklui svarbus duomuo yra teigiamą arba neigiamą reikšme turinti savybė nusakanti ar objekto duomenys yra cenzūruoti. Kaip minėta prieš tai, cenzūruoti duomenys yra tie, kurių įvykio mes dar neužfiksavome. Sukurti tokia duomenų savybę buvo nesudėtinga - tereikėjo pažymėti visus skelbimus, kurie surinko mažiau negu x taškų cenzūruotais. 

Atlikus duomenų atvaizdavimą galime pastebėti, kad duomenys beveik tobulai atitinka skirstinio įgaunamas formas (žr. pav. x). Net parametrai, kurie nebuvo dirbtinai sugeneruoti paklūsta pasiskirstymams ir sukurta forma primena vadinamą \textit{bell curve}. 

\subsection{Modelio kūrimas}

Prieš pradedant kurti modelį buvo pirma sukurta programa padedanti geriau susipažinti su statistikos pagrindais. Buvo sukurta programa generuojanti atsitiktinius skaičius pagal Weibull skirstinį, juos pateikiančius paprastam pilnai sujungtam neuroniniam tinklui ir, tinklo išvestyje, pateikianti prognozuojamus Weibull skirstinio parametrus. Turint parametrus, programai belikdavo paskaičiuoti kvantilį tam tikrame taške. Naudojantis daugeliu šios programos logikos buvo sukurti grafikai panaudoti ankstesniuose darbo skyriuose (žr. pav. x). Bekuriant šią programą buvo susidurta su problema, kad Tensorflow karkasas (kurį apgaubia Keras karkasas) palaiko tik tam tikrą kiekį skirstinių, kurių tarpe nebuvo Weibull skirstinio. Daugiau pasidomėjus buvo surasta, kad Tensorflow palaiko Weibull binominį objektą. Tai šiek tiek žemesnio lygio įrankis, negu Tensorflow Distribution objektas, bet atlikus šiek tiek papildomos logikos buvo galima pasiekti trokštamą rezultatą. Palyginimui, Distribution objektas leidžia tiesiogiai sukurti atsitiktinią atitinkamo skirstinio vertę. 

Modelio kūrimo procesas prasidėjo tinklo skirto WTTE sėkmingumui palyginti sudarymu. Šis tinklas buvo sukurtas naudojant Keras karkasą, Google Colab programavimo aplinkoje. Šis įrankis sudarė palankias sąlygas nesudėtingai, be didesnių sunkumų, dalintis programiniu kodu su bakalaurinio darbo vadovu, sutaupyti asmeninio kompiuterio resursų. Kurtas DNT, kaip minėta prieš tai, dalinasi daug architektūrinių sprendimų su pagrindiniu WTTE tinklu. Jis naudoja iš anksto apmokintą ResNet tinklą skirtą išgauti skelbimuose esančių paveiksliukų savybėms, jis pasitelkia Google sukurtu USE modeliu, kurio irgi yra iš anksto apmokintas ir yra skirtas apdoroti skelbimų aprašymus. Skaičių vektoriai gauti iš paveiksliukų ir iš skelbimų aprašymų tada yra sujungiami kartu su kitomis skelbimo savybėmis (rida, kaina ir t.t.). Gautas savybių vektorius pateikiamas pilnai sujungtam tinklui. Buvo bandoma daug įvairių hiperparametų ir sluoksnių kiekių minetąjąm pilnai sujungtam tinklui. Buvo bandomas plataus tinklo priėjimas, tai yra, turint mažai sluoksnių, bet, sluoksniuose, turint daug neuronų ir buvo bandoma siauro bet ilgo tinklo priėjimas. Pastarasis turėjo mažai neuronų, bet pasitelkė daug sluoksnių. Atlikus daug eksperimentų buvo pasirinkta naudoti tris plačius sluoksnius, nes jie pasiekė geriausius rezultatus (žr. lent. x).

\begin{table}[H]\footnotesize
  \centering
  \caption{ Rėmimosi DNT architektūrų bandymai ir tikslumai. Pasiektas tikslumas įvertinamas vidutiniška absoliuti paklaida \textit{(angl. Mean Absolute Error)}. Naudojama \textit{loss} funkcija - vidutinė kvardratinė paklaida.}
  {\begin{tabular}{|c|c|c|c|c|c|} \hline
    Pirmo sl. neuronų sk. & Tarpinų sl. neuronų sk. & Sluoksniai & Aktyvacijos f-ja & Pasiektas tikslumas & Epochos \\
    \hline
    20000 & 1000 & 5  &   Rectifier  & 40.7847  & 100 \\
    \hline
    10000 & 1000 & 5  &   Rectifier  & 41.3801  & 100 \\
    \hline
    5000 & 1000 & 5  &   Rectifier  & 41.3647  & 100 \\
    \hline
  \end{tabular}}
  \label{tab:table example}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.8]{img/RESULT1}
  \caption{ DNT padarytų spėjimų atitikimas tikriems duomenims. }
  \label{img:RESULT1}
\end{figure}

Sukūrus bazinį palyginimui skirtą tinklą buvo galima imtis pagrindinio tinklo predėjimo. Naujasis WTTE tinklas dalinasi visais architektūriniais sprendimais kaip ir bazinis išskyrus aktyvacijos ir \textit{loss} funkcijas, ir, taip pat, cenzūruotų duomenų panaudojimą. Kadangi, naujasis modelis turi naudoti specialiai pritaikytas aktyvacijos ir \textit{loss} funkcijas buvo būtina skirti laiko ir pastangų nišiniam Keras karkaso specialių (angl. custom) funkcijų funkcionalumui.išsiaiškinti. Ilgai netrukus buvo susidurta su problema - pritaikius tinklą savo specialioms reikmėms jis pradėjo, kaip \textit{loss} funkcijos rezultatą išvedinėti „NaN“ reikšmę. 

\sectionnonum{Rezultatai ir išvados}

% Nors sukurti deramo prototipo spręsti įvardintam uždaviniui, grubiai tariant, nepavyko, darbas atvėrė galimybę stipriam žinių ir patirties pamatui susiformuoti. Dėl šio pamato tolimesnieji autoriaus tyrimai šioje srityje tūrėtų būti sėkmingesni.

% Rezultatų ir išvadų dalyje turi būti aiškiai išdėstomi pagrindiniai darbo
% rezultatai (kažkas išanalizuota, kažkas sukurta, kažkas įdiegta) ir pateikiamos
% išvados (daromi nagrinėtų problemų sprendimo metodų palyginimai, teikiamos
% rekomendacijos, akcentuojamos naujovės).
\printbibliography[heading=bibintoc]  % Šaltinių sąraše nurodoma panaudota
% literatūra, kitokie šaltiniai. Abėcėlės tvarka išdėstomi darbe panaudotų
% (cituotų, perfrazuotų ar bent paminėtų) mokslo leidinių, kitokių publikacijų
% bibliografiniai aprašai.  Šaltinių sąrašas spausdinamas iš naujo puslapio.
% Aprašai pateikiami netransliteruoti. Šaltinių sąraše negali būti tokių
% šaltinių, kurie nebuvo paminėti tekste.

% \sectionnonum{Sąvokų apibrėžimai}
\sectionnonum{Santrumpos}


\begin{enumerate}
  \item DNT - dirbtinis neuroninis tinklas \textit{(angl. artificial neural network)} tai tarpusavyje sujungtų mazgų grupė primenanti smegenų neuronų tinklą.
  \item CNN - konvoliucinis neuroninis tinklas \textit{(angl. convolutional neural network)} tai neuroninių tinklų klasė, dažniausiai naudojama vaizdų analizei.
  \item ResNet - giliusis liekaninis tinklas \textit{(angl. residual neural network)} tai DNT išsiskiriantis naudojamais sujungimais skirtais praleisti sluoksnius.
  \item FNN - į priekį sklendantis neuroninis tinklas \textit{(angl. feedforward neural network)} tai neuroninis tinklas kurio kievienas mazgas, yra sujungtas su prieš tai esančio sluoksnio kiekvienu mazgu. Jame mazgų jungtys nesuformuoja ciklo, informacija sklinda tiktai į priekį.
  \item Išeigos požymių žemėlapis \textit{(angl. output feature map)} - tai konvoliucinio sluoksnio filtro rastų požymių rinkinys.
  \item Konvoliucinis sluoksnis \textit{(angl. convolutional layer)} - tai vienas iš CNN sluoksnių.
  \item API \textit{(application programing interface)} - rinkinys protokolų, subrutininių definicijų ir įrankių skirtų kurti programinę įrangą.
  \item GDPR \textit{(angl. general data protection regulation)} - duomenų privatumo apsaugos aktas taikomas kiekvienam žmogui Europos Sąjungoje.
  \item SVM \textit{(angl. support vector machine)} - mokinimo su mokytoju DNT modelis, kuris naudoja paraminius vektorius \textit{(angl. support vectors)}, o ne sluoksnių metodą.
  \item TOR \textit{(angl. the onion router)} - anoniminį naršymą įgalinantis protokolas gebantis dinamiškai keisti IP adresą.
  \item DDOS \textit{(angl. denial of service attack)} - kibernetinės atakos būdas peremtas dideliu duomenų srautu.
  \item GN - gilusis neuroninis.
\end{enumerate}
% Sąvokų apibrėžimai ir santrumpų sąrašas sudaromas tada, kai darbo tekste
% vartojami specialūs paaiškinimo reikalaujantys terminai ir rečiau sutinkamos
% santrumpos.

\appendix  % Priedai
% Prieduose gali būti pateikiama pagalbinė, ypač darbo autoriaus savarankiškai
% parengta, medžiaga. Savarankiški priedai gali būti pateikiami ir
% kompaktiniame diske. Priedai taip pat numeruojami ir vadinami. Darbo tekstas
% su priedais susiejamas nuorodomis.
\section{Sukurtų aplikacijų ir duomenų rinkinio repozitorija}

https://github.com/ignas-mif/Kursinis2018

\end{document}